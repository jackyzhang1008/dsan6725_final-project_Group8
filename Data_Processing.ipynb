{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ccc8581-cfc6-40ef-be45-a927d0f91d33",
   "metadata": {},
   "source": [
    "# Data Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a593452-5945-4054-9078-c597ec88ea68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 4 threads to week-3-channel.json\n",
      "✅ Saved 5 threads to aws-channel.json\n",
      "✅ Saved 5 threads to week-2-channel.json\n",
      "✅ Saved 5 threads to week-1-channel.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"./data\")\n",
    "OUTPUT_DIR = Path(\"./parsed\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def parse_markdown_file(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    channel = \"\"\n",
    "    threads = []\n",
    "    current_thread = None\n",
    "    current_messages = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        if line.startswith(\"# Channel \"):  # Channel name\n",
    "            channel = line[len(\"# Channel \"):].strip()\n",
    "\n",
    "\n",
    "        elif line.startswith(\"## Thread: \"):  # New thread\n",
    "            # Save the previous thread\n",
    "            if current_thread:\n",
    "                threads.append(current_thread)\n",
    "\n",
    "            thread_title = line.replace(\"## Thread: \", \"\").strip()\n",
    "            current_thread = {\n",
    "                \"channel\": channel,\n",
    "                \"thread_title\": thread_title,\n",
    "                \"messages\": []\n",
    "            }\n",
    "\n",
    "        elif re.match(r\"\\*\\*.+\\*\\* \\[.*\\]\", line):  # Message line\n",
    "            match = re.match(r\"\\*\\*(.+)\\*\\* \\[(.+?)\\]\", line)\n",
    "            if match:\n",
    "                user, timestamp = match.groups()\n",
    "                current_messages = {\n",
    "                    \"user\": user.strip(),\n",
    "                    \"timestamp\": timestamp.strip(),\n",
    "                    \"text\": \"\"\n",
    "                }\n",
    "                current_thread[\"messages\"].append(current_messages)\n",
    "\n",
    "        elif line and current_messages:\n",
    "            # Add to the last message's text\n",
    "            current_messages[\"text\"] += (line + \" \")\n",
    "\n",
    "    if current_thread:\n",
    "        threads.append(current_thread)\n",
    "\n",
    "    return threads\n",
    "\n",
    "def parse_and_save_each_file():\n",
    "    for file in DATA_DIR.glob(\"*.md\"):\n",
    "        threads = parse_markdown_file(file)\n",
    "        output_path = OUTPUT_DIR / (file.stem + \".json\")\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(threads, f, indent=2)\n",
    "        print(f\"✅ Saved {len(threads)} threads to {output_path.name}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parse_and_save_each_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f859b621-226e-47df-9f24-487ea078b49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Parsed 19 threads and saved to parsed_threads.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"./data\")\n",
    "\n",
    "def parse_markdown_file(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    channel = \"\"\n",
    "    threads = []\n",
    "    current_thread = None\n",
    "    current_messages = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        if line.startswith(\"# Channel\"):  # Channel name\n",
    "             channel = line[len(\"# Channel \"):].strip()\n",
    "\n",
    "        elif line.startswith(\"## Thread: \"):  # New thread\n",
    "            # Save the previous thread\n",
    "            if current_thread:\n",
    "                threads.append(current_thread)\n",
    "\n",
    "            thread_title = line.replace(\"## Thread: \", \"\").strip()\n",
    "            current_thread = {\n",
    "                \"channel\": channel,\n",
    "                \"thread_title\": thread_title,\n",
    "                \"messages\": []\n",
    "            }\n",
    "\n",
    "        elif re.match(r\"\\*\\*.+\\*\\* \\[.*\\]\", line):  # Message line\n",
    "            match = re.match(r\"\\*\\*(.+)\\*\\* \\[(.+?)\\]\", line)\n",
    "            if match:\n",
    "                user, timestamp = match.groups()\n",
    "                current_messages = {\n",
    "                    \"user\": user.strip(),\n",
    "                    \"timestamp\": timestamp.strip(),\n",
    "                    \"text\": \"\"\n",
    "                }\n",
    "                current_thread[\"messages\"].append(current_messages)\n",
    "\n",
    "        elif line and current_messages:\n",
    "            # Add to the last message's text\n",
    "            current_messages[\"text\"] += (line + \" \")\n",
    "\n",
    "    # Append the last thread\n",
    "    if current_thread:\n",
    "        threads.append(current_thread)\n",
    "\n",
    "    return threads\n",
    "\n",
    "def parse_all_files():\n",
    "    all_threads = []\n",
    "\n",
    "    for file in DATA_DIR.glob(\"*.md\"):\n",
    "        threads = parse_markdown_file(file)\n",
    "        all_threads.extend(threads)\n",
    "\n",
    "    return all_threads\n",
    "\n",
    "def save_as_json(data, output_path=\"parsed/parsed_threads.json\"):\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parsed_threads = parse_all_files()\n",
    "    save_as_json(parsed_threads)\n",
    "    print(f\"✅ Parsed {len(parsed_threads)} threads and saved to parsed_threads.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e64430-4465-4aef-94e3-e6f831dbee0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
